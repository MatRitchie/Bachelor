{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwhuHriCGPeP",
        "v4yQED8vGZuo",
        "J9IcCbKQG3SW"
      ],
      "authorship_tag": "ABX9TyPI1DoR/mZH+u4ytJOYj99T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatRitchie/Bachelor/blob/main/seq2seq_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwhuHriCGPeP"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCyMQ_ADg7pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820980e1-b42a-45e8-b8a9-95bc8d7dff68"
      },
      "source": [
        "!pip install folium==0.2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 14.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp36-none-any.whl size=79980 sha256=204bcea1464d162b78303cb4ee541a068ee33a6def645beb62ba29c65f012f6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwEWi2efR9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d7c9b7-9406-43cd-ac0b-2940cc5ca749"
      },
      "source": [
        "!pip install --upgrade urllib3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting urllib3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 7.4MB/s \n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.2 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.26.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yXNPmGkfhl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a404e320-4ce1-417e-e43d-16ff1353e52a"
      },
      "source": [
        "!pip install registrable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting registrable\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/47/6370d9389664f1af31de4048934faeb681035a079ddc3d284a366875e755/registrable-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: registrable\n",
            "Successfully installed registrable-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO6nbdH3IBQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b312813-b39c-46ba-b356-dd8e0dd4842c"
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/f5/f4dd3424b3ae9dec0a55ae7f7f34ada3ee60e4b10a187d2ba7384c698e09/allennlp-1.3.0-py3-none-any.whl (506kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.7.0+cu101)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting transformers<4.1,>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 22.2MB/s \n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/d5/1cc282dc23346a43aab461bf2e8c36593aacd34242bee1a13fa750db0cfe/jsonpickle-1.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 24.6MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/4c/e81c2f215e93a6cb5efdaa991669e3ef1ec6ecfe4407c582c3dfc7d2c281/boto3-1.16.56-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (1.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (51.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (3.3.0)\n",
            "Collecting botocore<1.20.0,>=1.19.56\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/72/c904c62945127699aac8aa5bbd508ec851d55da46aaf1072c061de3eb6fa/botocore-1.19.56-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 56.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.12.5)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<4.1,>=4.0->allennlp) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.1,>=4.0->allennlp) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.56->boto3<2.0,>=1.14->allennlp) (2.8.1)\n",
            "Building wheels for collected packages: jsonnet, overrides, sacremoses\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp36-cp36m-linux_x86_64.whl size=3387897 sha256=c85f0ac0f7a0add53c3c4b9fa79de01c2eb07d982b6eda7356c876f315405524\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10175 sha256=daaaaca0b3c27da1c482bef13a3cea6394c7940141c907fb375fda834f480738\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=652b07d06f7001dc85d9aaf2b9e2fd999a536e597a504d1c5335b5db81318765\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built jsonnet overrides sacremoses\n",
            "Installing collected packages: tensorboardX, tokenizers, sacremoses, transformers, jsonpickle, jsonnet, jmespath, urllib3, botocore, s3transfer, boto3, sentencepiece, overrides, allennlp\n",
            "  Found existing installation: urllib3 1.26.2\n",
            "    Uninstalling urllib3-1.26.2:\n",
            "      Successfully uninstalled urllib3-1.26.2\n",
            "Successfully installed allennlp-1.3.0 boto3-1.16.56 botocore-1.19.56 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-1.4.2 overrides-3.1.0 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95 tensorboardX-2.1 tokenizers-0.9.4 transformers-4.0.1 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X58EMH44oJ3r",
        "outputId": "4e56d13d-a0ee-4389-efc7-cd67aa6d92d2"
      },
      "source": [
        "!pip install --pre allennlp-models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp-models\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/e8/3eab9b645a1bd4abac892229952572cd8df5b5de3bd316774f845cbd10f1/allennlp_models-1.3.0-py3-none-any.whl (378kB)\n",
            "\r\u001b[K     |▉                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 17.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 51kB 19.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 102kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 204kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 256kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 358kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: allennlp<1.4,>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp-models) (1.3.0)\n",
            "Collecting conllu==4.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/20/39bf21e3a0304c874c40c9cec96e3f70d2ef4b1ada3585f7dbee91dc8c05/conllu-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp-models) (3.2.5)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting py-rouge==1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.8.0,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from allennlp-models) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (4.41.1)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (3.0.12)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (2.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (2.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (0.1.95)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (2.1)\n",
            "Requirement already satisfied: transformers<4.1,>=4.0 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (4.0.1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (0.17.0)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (3.1.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (0.8)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (3.6.4)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (1.19.5)\n",
            "Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.6/dist-packages (from allennlp<1.4,>=1.3.0->allennlp-models) (1.16.56)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp-models) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp-models) (0.2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.7.0->allennlp-models) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.7.0->allennlp-models) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp<1.4,>=1.3.0->allennlp-models) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp<1.4,>=1.3.0->allennlp-models) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp<1.4,>=1.3.0->allennlp-models) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp<1.4,>=1.3.0->allennlp-models) (1.25.11)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp<1.4,>=1.3.0->allennlp-models) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (51.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp<1.4,>=1.3.0->allennlp-models) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp<1.4,>=1.3.0->allennlp-models) (3.12.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (20.8)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp<1.4,>=1.3.0->allennlp-models) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp<1.4,>=1.3.0->allennlp-models) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp<1.4,>=1.3.0->allennlp-models) (20.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp<1.4,>=1.3.0->allennlp-models) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp<1.4,>=1.3.0->allennlp-models) (1.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp<1.4,>=1.3.0->allennlp-models) (3.3.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp<1.4,>=1.3.0->allennlp-models) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.56 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp<1.4,>=1.3.0->allennlp-models) (1.19.56)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp<1.4,>=1.3.0->allennlp-models) (0.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<4.1,>=4.0->allennlp<1.4,>=1.3.0->allennlp-models) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp<1.4,>=1.3.0->allennlp-models) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.56->boto3<2.0,>=1.14->allennlp<1.4,>=1.3.0->allennlp-models) (2.8.1)\n",
            "Building wheels for collected packages: word2number, ftfy\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=7a615d65e6946d2636be89bafbaac8fa802271ca56115a6f2a5bb423b5ed6eb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=fcb6f41706d3c9258ffec9235a78c2acc685c567e98a73dac89071cd499592d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "Successfully built word2number ftfy\n",
            "Installing collected packages: conllu, word2number, py-rouge, ftfy, allennlp-models\n",
            "Successfully installed allennlp-models-1.3.0 conllu-4.2.1 ftfy-5.8 py-rouge-1.1 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4yQED8vGZuo"
      },
      "source": [
        "# Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VzxyUCgLG3Q",
        "outputId": "aa606b65-aad2-448a-8fb9-2e2484ec5b55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvjtf1JeGy8G"
      },
      "source": [
        "# Train model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT83bZa16QB6",
        "outputId": "d1d3bf81-0b15-4aa1-e8b6-675176cb1cc8"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Bachelor_Project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Bachelor_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d20Ev23BajnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca345c89-6f39-4171-ce20-ac6a0ad6886c"
      },
      "source": [
        "!allennlp train '/content/gdrive/My Drive/Bachelor_Project/training_config/seq2seq_config_1.json' -s Output_seq2seq/ -f "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-13 11:53:12.477715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-13 11:53:16,096 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n",
            "2021-01-13 11:53:17,234 - INFO - allennlp.common.params - include_in_archive = None\n",
            "2021-01-13 11:53:17,236 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2021-01-13 11:53:17,237 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2021-01-13 11:53:17,237 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2021-01-13 11:53:17,238 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n",
            "2021-01-13 11:53:17,240 - INFO - allennlp.common.params - type = default\n",
            "2021-01-13 11:53:17,241 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 11:53:17,241 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 11:53:17,242 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 11:53:17,242 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 11:53:17,242 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 11:53:17,242 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 11:53:17,243 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 11:53:17,243 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 11:53:17,244 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 11:53:17,244 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 11:53:17,244 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 11:53:17,244 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 11:53:17,245 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 11:53:17,245 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 11:53:17,245 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 11:53:17,245 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 11:53:17,245 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 11:53:17,246 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 11:53:17,246 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 11:53:17,246 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 11:53:17,246 - INFO - allennlp.common.params - train_data_path = /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_train.csv\n",
            "2021-01-13 11:53:17,247 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f6d22ec90b8>\n",
            "2021-01-13 11:53:17,247 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2021-01-13 11:53:17,247 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2021-01-13 11:53:17,248 - INFO - allennlp.common.params - validation_data_path = /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_dev.csv\n",
            "2021-01-13 11:53:17,248 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2021-01-13 11:53:17,248 - INFO - allennlp.common.params - test_data_path = None\n",
            "2021-01-13 11:53:17,248 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2021-01-13 11:53:17,249 - INFO - allennlp.common.params - batch_weight_key = \n",
            "2021-01-13 11:53:17,249 - INFO - allennlp.training.util - Reading training data from /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_train.csv\n",
            "reading instances: 0it [00:00, ?it/s]2021-01-13 11:53:17,251 - INFO - allennlp_models.generation.dataset_readers.seq2seq - Reading instances from lines in file at: /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_train.csv\n",
            "reading instances: 217it [00:00, 2235.14it/s]\n",
            "2021-01-13 11:53:17,347 - INFO - allennlp.training.util - Reading validation data from /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_dev.csv\n",
            "reading instances: 0it [00:00, ?it/s]2021-01-13 11:53:17,349 - INFO - allennlp_models.generation.dataset_readers.seq2seq - Reading instances from lines in file at: /content/gdrive/My Drive/Kaggle/LYRICS_DATASET_dev.csv\n",
            "reading instances: 73it [00:00, 378.10it/s]\n",
            "2021-01-13 11:53:17,541 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-01-13 11:53:17,542 - INFO - allennlp.common.params - min_count = None\n",
            "2021-01-13 11:53:17,542 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2021-01-13 11:53:17,542 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2021-01-13 11:53:17,542 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2021-01-13 11:53:17,543 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2021-01-13 11:53:17,543 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2021-01-13 11:53:17,543 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2021-01-13 11:53:17,543 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2021-01-13 11:53:17,544 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2021-01-13 11:53:17,544 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "building vocab: 290it [00:00, 5736.30it/s]\n",
            "2021-01-13 11:53:17,607 - INFO - allennlp.common.params - model.type = composed_seq2seq\n",
            "2021-01-13 11:53:17,608 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-01-13 11:53:17,609 - INFO - allennlp.common.params - model.source_text_embedder.type = basic\n",
            "2021-01-13 11:53:17,609 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.type = embedding\n",
            "2021-01-13 11:53:17,610 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.embedding_dim = 256\n",
            "2021-01-13 11:53:17,610 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.num_embeddings = None\n",
            "2021-01-13 11:53:17,610 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.projection_dim = None\n",
            "2021-01-13 11:53:17,611 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.weight = None\n",
            "2021-01-13 11:53:17,611 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.padding_index = None\n",
            "2021-01-13 11:53:17,611 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.trainable = True\n",
            "2021-01-13 11:53:17,611 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.max_norm = None\n",
            "2021-01-13 11:53:17,612 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.norm_type = 2.0\n",
            "2021-01-13 11:53:17,612 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
            "2021-01-13 11:53:17,612 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.sparse = False\n",
            "2021-01-13 11:53:17,612 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
            "2021-01-13 11:53:17,612 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.pretrained_file = None\n",
            "2021-01-13 11:53:17,626 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
            "2021-01-13 11:53:17,626 - INFO - allennlp.common.params - model.encoder.input_dim = 256\n",
            "2021-01-13 11:53:17,627 - INFO - allennlp.common.params - model.encoder.hidden_dim = 256\n",
            "2021-01-13 11:53:17,627 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
            "2021-01-13 11:53:17,627 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
            "2021-01-13 11:53:17,627 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
            "2021-01-13 11:53:17,628 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
            "2021-01-13 11:53:17,628 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
            "2021-01-13 11:53:17,628 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
            "2021-01-13 11:53:17,628 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
            "2021-01-13 11:53:17,629 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
            "2021-01-13 11:53:17,633 - INFO - allennlp.common.params - model.decoder.type = auto_regressive_seq_decoder\n",
            "2021-01-13 11:53:17,634 - INFO - allennlp.common.params - model.decoder.decoder_net.type = stacked_self_attention\n",
            "2021-01-13 11:53:17,634 - INFO - allennlp.common.params - model.decoder.decoder_net.decoding_dim = 256\n",
            "2021-01-13 11:53:17,634 - INFO - allennlp.common.params - model.decoder.decoder_net.target_embedding_dim = 256\n",
            "2021-01-13 11:53:17,635 - INFO - allennlp.common.params - model.decoder.decoder_net.feedforward_hidden_dim = 128\n",
            "2021-01-13 11:53:17,635 - INFO - allennlp.common.params - model.decoder.decoder_net.num_layers = 1\n",
            "2021-01-13 11:53:17,635 - INFO - allennlp.common.params - model.decoder.decoder_net.num_attention_heads = 8\n",
            "2021-01-13 11:53:17,635 - INFO - allennlp.common.params - model.decoder.decoder_net.use_positional_encoding = True\n",
            "2021-01-13 11:53:17,636 - INFO - allennlp.common.params - model.decoder.decoder_net.positional_encoding_max_steps = 5000\n",
            "2021-01-13 11:53:17,636 - INFO - allennlp.common.params - model.decoder.decoder_net.dropout_prob = 0.1\n",
            "2021-01-13 11:53:17,636 - INFO - allennlp.common.params - model.decoder.decoder_net.residual_dropout_prob = 0.2\n",
            "2021-01-13 11:53:17,636 - INFO - allennlp.common.params - model.decoder.decoder_net.attention_dropout_prob = 0.1\n",
            "2021-01-13 11:53:17,659 - INFO - allennlp.common.params - model.decoder.max_decoding_steps = 20\n",
            "2021-01-13 11:53:17,660 - INFO - allennlp.common.params - model.decoder.target_embedder.embedding_dim = 256\n",
            "2021-01-13 11:53:17,660 - INFO - allennlp.common.params - model.decoder.target_embedder.num_embeddings = None\n",
            "2021-01-13 11:53:17,661 - INFO - allennlp.common.params - model.decoder.target_embedder.projection_dim = None\n",
            "2021-01-13 11:53:17,661 - INFO - allennlp.common.params - model.decoder.target_embedder.weight = None\n",
            "2021-01-13 11:53:17,661 - INFO - allennlp.common.params - model.decoder.target_embedder.padding_index = None\n",
            "2021-01-13 11:53:17,662 - INFO - allennlp.common.params - model.decoder.target_embedder.trainable = True\n",
            "2021-01-13 11:53:17,662 - INFO - allennlp.common.params - model.decoder.target_embedder.max_norm = None\n",
            "2021-01-13 11:53:17,662 - INFO - allennlp.common.params - model.decoder.target_embedder.norm_type = 2.0\n",
            "2021-01-13 11:53:17,662 - INFO - allennlp.common.params - model.decoder.target_embedder.scale_grad_by_freq = False\n",
            "2021-01-13 11:53:17,663 - INFO - allennlp.common.params - model.decoder.target_embedder.sparse = False\n",
            "2021-01-13 11:53:17,663 - INFO - allennlp.common.params - model.decoder.target_embedder.vocab_namespace = tokens\n",
            "2021-01-13 11:53:17,664 - INFO - allennlp.common.params - model.decoder.target_embedder.pretrained_file = None\n",
            "2021-01-13 11:53:17,677 - INFO - allennlp.common.params - model.decoder.target_namespace = tokens\n",
            "2021-01-13 11:53:17,678 - INFO - allennlp.common.params - model.decoder.tie_output_embedding = False\n",
            "2021-01-13 11:53:17,678 - INFO - allennlp.common.params - model.decoder.scheduled_sampling_ratio = 0.5\n",
            "2021-01-13 11:53:17,679 - INFO - allennlp.common.params - model.decoder.label_smoothing_ratio = None\n",
            "2021-01-13 11:53:17,679 - INFO - allennlp.common.params - model.decoder.beam_size = 8\n",
            "2021-01-13 11:53:17,679 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.type = bleu\n",
            "2021-01-13 11:53:17,680 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.ngram_weights = [0.5, 0.5, 0, 0, 0]\n",
            "2021-01-13 11:53:17,680 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.exclude_indices = None\n",
            "2021-01-13 11:53:17,681 - INFO - allennlp.common.params - model.decoder.token_based_metric = None\n",
            "2021-01-13 11:53:17,694 - INFO - allennlp.common.params - model.tied_source_embedder_key = None\n",
            "2021-01-13 11:53:17,695 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f6d22dfbfd0>\n",
            "2021-01-13 11:53:17,695 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-01-13 11:53:17,696 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-01-13 11:53:17,696 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-13 11:53:17,696 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-13 11:53:17,697 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-13 11:53:17,698 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-13 11:53:17,699 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-13 11:53:17,700 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.bias\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.weight\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _decoder.target_embedder.weight\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-13 11:53:17,701 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
            "2021-01-13 11:53:17,702 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-13 11:53:17,703 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-13 11:53:17,703 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-13 11:53:17,703 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-13 11:53:17,703 - INFO - allennlp.nn.initializers -    _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-13 11:53:17,727 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2021-01-13 11:53:17,729 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2021-01-13 11:53:17,729 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2021-01-13 11:53:17,729 - INFO - allennlp.common.params - data_loader.sampler = None\n",
            "2021-01-13 11:53:17,730 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2021-01-13 11:53:17,730 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2021-01-13 11:53:17,730 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2021-01-13 11:53:17,731 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2021-01-13 11:53:17,731 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2021-01-13 11:53:17,731 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2021-01-13 11:53:17,731 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2021-01-13 11:53:17,732 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket\n",
            "2021-01-13 11:53:17,732 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 10\n",
            "2021-01-13 11:53:17,733 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None\n",
            "2021-01-13 11:53:17,733 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0\n",
            "2021-01-13 11:53:17,733 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False\n",
            "2021-01-13 11:53:17,734 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2021-01-13 11:53:17,735 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2021-01-13 11:53:17,735 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2021-01-13 11:53:17,736 - INFO - allennlp.common.params - data_loader.sampler = None\n",
            "2021-01-13 11:53:17,736 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2021-01-13 11:53:17,736 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2021-01-13 11:53:17,737 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2021-01-13 11:53:17,737 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2021-01-13 11:53:17,737 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2021-01-13 11:53:17,738 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2021-01-13 11:53:17,738 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2021-01-13 11:53:17,739 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket\n",
            "2021-01-13 11:53:17,739 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 10\n",
            "2021-01-13 11:53:17,740 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None\n",
            "2021-01-13 11:53:17,740 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0\n",
            "2021-01-13 11:53:17,740 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False\n",
            "2021-01-13 11:53:17,741 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2021-01-13 11:53:17,742 - INFO - allennlp.common.params - trainer.patience = 20\n",
            "2021-01-13 11:53:17,742 - INFO - allennlp.common.params - trainer.validation_metric = +BLEU\n",
            "2021-01-13 11:53:17,742 - INFO - allennlp.common.params - trainer.num_epochs = 100\n",
            "2021-01-13 11:53:17,743 - INFO - allennlp.common.params - trainer.cuda_device = -1\n",
            "2021-01-13 11:53:17,743 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2021-01-13 11:53:17,743 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2021-01-13 11:53:17,744 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2021-01-13 11:53:17,744 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2021-01-13 11:53:17,744 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2021-01-13 11:53:17,744 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2021-01-13 11:53:17,745 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2021-01-13 11:53:17,745 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2021-01-13 11:53:17,746 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2021-01-13 11:53:17,746 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f6d22f18908>\n",
            "2021-01-13 11:53:17,746 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2021-01-13 11:53:17,746 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x7f6d22f18b38>\n",
            "2021-01-13 11:53:17,747 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2021-01-13 11:53:17,747 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2021-01-13 11:53:17,747 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2021-01-13 11:53:17,747 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2021-01-13 11:53:17,748 - INFO - allennlp.common.params - trainer.optimizer.type = adam\n",
            "2021-01-13 11:53:17,749 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2021-01-13 11:53:17,749 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.01\n",
            "2021-01-13 11:53:17,749 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2021-01-13 11:53:17,750 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2021-01-13 11:53:17,750 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0\n",
            "2021-01-13 11:53:17,751 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2021-01-13 11:53:17,751 - INFO - allennlp.training.optimizers - Number of trainable parameters: 5060910\n",
            "2021-01-13 11:53:17,753 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2021-01-13 11:53:17,753 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2021-01-13 11:53:17,754 - INFO - allennlp.common.util - _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-13 11:53:17,754 - INFO - allennlp.common.util - _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-13 11:53:17,755 - INFO - allennlp.common.util - _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-13 11:53:17,755 - INFO - allennlp.common.util - _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-13 11:53:17,756 - INFO - allennlp.common.util - _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-13 11:53:17,756 - INFO - allennlp.common.util - _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-13 11:53:17,756 - INFO - allennlp.common.util - _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-13 11:53:17,757 - INFO - allennlp.common.util - _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-13 11:53:17,757 - INFO - allennlp.common.util - _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-13 11:53:17,757 - INFO - allennlp.common.util - _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-13 11:53:17,758 - INFO - allennlp.common.util - _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-13 11:53:17,758 - INFO - allennlp.common.util - _encoder.layer_norm_0.gamma\n",
            "2021-01-13 11:53:17,758 - INFO - allennlp.common.util - _encoder.layer_norm_0.beta\n",
            "2021-01-13 11:53:17,759 - INFO - allennlp.common.util - _decoder.target_embedder.weight\n",
            "2021-01-13 11:53:17,759 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-13 11:53:17,760 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-13 11:53:17,760 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-13 11:53:17,760 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-13 11:53:17,761 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-13 11:53:17,761 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-13 11:53:17,761 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-13 11:53:17,761 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-13 11:53:17,762 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-13 11:53:17,762 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-13 11:53:17,762 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-13 11:53:17,762 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-13 11:53:17,763 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-13 11:53:17,763 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-13 11:53:17,763 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-13 11:53:17,763 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-13 11:53:17,763 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-13 11:53:17,764 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-13 11:53:17,764 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-13 11:53:17,764 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-13 11:53:17,765 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-13 11:53:17,765 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-13 11:53:17,765 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-13 11:53:17,766 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-13 11:53:17,766 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-13 11:53:17,767 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-13 11:53:17,767 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-13 11:53:17,767 - INFO - allennlp.common.util - _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-13 11:53:17,768 - INFO - allennlp.common.util - _decoder._output_projection_layer.weight\n",
            "2021-01-13 11:53:17,768 - INFO - allennlp.common.util - _decoder._output_projection_layer.bias\n",
            "2021-01-13 11:53:17,768 - INFO - allennlp.common.params - type = default\n",
            "2021-01-13 11:53:17,769 - INFO - allennlp.common.params - keep_serialized_model_every_num_seconds = None\n",
            "2021-01-13 11:53:17,769 - INFO - allennlp.common.params - num_serialized_models_to_keep = 2\n",
            "2021-01-13 11:53:17,773 - INFO - allennlp.common.params - model_save_interval = None\n",
            "2021-01-13 11:53:17,777 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2021-01-13 11:53:17,777 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2021-01-13 11:53:17,778 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2021-01-13 11:53:17,778 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2021-01-13 11:53:17,779 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2021-01-13 11:53:17,779 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2021-01-13 11:53:17,794 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2021-01-13 11:53:17,795 - INFO - allennlp.training.trainer - Epoch 0/99\n",
            "2021-01-13 11:53:17,795 - INFO - allennlp.training.trainer - Worker 0 memory usage: 593M\n",
            "2021-01-13 11:53:17,795 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/22 [00:00<?, ?it/s]2021-01-13 11:53:17,796 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one\n",
            "2021-01-13 11:53:17,799 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['source_tokens'] as the sorting keys\n",
            "batch_loss: 6.7550, loss: 7.0015 ||: 100%|##########| 22/22 [00:27<00:00,  1.26s/it]\n",
            "2021-01-13 11:53:45,665 - INFO - allennlp.training.trainer - Validating\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]2021-01-13 11:53:45,666 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one\n",
            "2021-01-13 11:53:45,669 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['source_tokens'] as the sorting keys\n",
            "BLEU: 0.0000, batch_loss: 6.5775, loss: 6.8296 ||: 100%|##########| 8/8 [00:05<00:00,  1.41it/s]\n",
            "2021-01-13 11:53:51,335 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 11:53:51,335 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 11:53:51,337 - INFO - allennlp.training.tensorboard_writer - loss               |     7.001  |     6.830\n",
            "2021-01-13 11:53:51,338 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   593.059  |       N/A\n",
            "2021-01-13 11:53:51,497 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'Output_seq2seq//best.th'.\n",
            "2021-01-13 11:53:51,661 - INFO - allennlp.training.trainer - Epoch duration: 0:00:33.866803\n",
            "2021-01-13 11:53:51,663 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:55:52\n",
            "2021-01-13 11:53:51,663 - INFO - allennlp.training.trainer - Epoch 1/99\n",
            "2021-01-13 11:53:51,664 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 11:53:51,664 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 5.1297, loss: 5.6546 ||: 100%|##########| 22/22 [00:56<00:00,  2.56s/it]\n",
            "2021-01-13 11:54:48,163 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.8151, loss: 7.1714 ||: 100%|##########| 8/8 [00:03<00:00,  2.30it/s]\n",
            "2021-01-13 11:54:51,642 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 11:54:51,643 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 11:54:51,644 - INFO - allennlp.training.tensorboard_writer - loss               |     5.655  |     7.171\n",
            "2021-01-13 11:54:51,646 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.449  |       N/A\n",
            "2021-01-13 11:54:51,813 - INFO - allennlp.training.trainer - Epoch duration: 0:01:00.149705\n",
            "2021-01-13 11:54:51,814 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:16:46\n",
            "2021-01-13 11:54:51,814 - INFO - allennlp.training.trainer - Epoch 2/99\n",
            "2021-01-13 11:54:51,815 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 11:54:51,816 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.7300, loss: 4.7723 ||: 100%|##########| 22/22 [01:48<00:00,  4.92s/it]\n",
            "2021-01-13 11:56:40,230 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 8.0293, loss: 7.4811 ||: 100%|##########| 8/8 [00:04<00:00,  1.70it/s]\n",
            "2021-01-13 11:56:44,949 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 11:56:44,949 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 11:56:44,951 - INFO - allennlp.training.tensorboard_writer - loss               |     4.772  |     7.481\n",
            "2021-01-13 11:56:44,952 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.703  |       N/A\n",
            "2021-01-13 11:56:45,125 - INFO - allennlp.training.trainer - Epoch duration: 0:01:53.311061\n",
            "2021-01-13 11:56:45,126 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:51:43\n",
            "2021-01-13 11:56:45,126 - INFO - allennlp.training.trainer - Epoch 3/99\n",
            "2021-01-13 11:56:45,126 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 11:56:45,127 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.5563, loss: 4.5552 ||: 100%|##########| 22/22 [01:45<00:00,  4.78s/it]\n",
            "2021-01-13 11:58:30,402 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.5165, loss: 7.2624 ||: 100%|##########| 8/8 [00:05<00:00,  1.54it/s]\n",
            "2021-01-13 11:58:35,604 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 11:58:35,604 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 11:58:35,605 - INFO - allennlp.training.tensorboard_writer - loss               |     4.555  |     7.262\n",
            "2021-01-13 11:58:35,606 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.703  |       N/A\n",
            "2021-01-13 11:58:35,838 - INFO - allennlp.training.trainer - Epoch duration: 0:01:50.712044\n",
            "2021-01-13 11:58:35,838 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:07:13\n",
            "2021-01-13 11:58:35,839 - INFO - allennlp.training.trainer - Epoch 4/99\n",
            "2021-01-13 11:58:35,839 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 11:58:35,839 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.9492, loss: 4.5155 ||: 100%|##########| 22/22 [01:26<00:00,  3.94s/it]\n",
            "2021-01-13 12:00:02,581 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.0998, loss: 6.8285 ||: 100%|##########| 8/8 [00:04<00:00,  1.94it/s]\n",
            "2021-01-13 12:00:06,712 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:00:06,713 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:00:06,714 - INFO - allennlp.training.tensorboard_writer - loss               |     4.515  |     6.829\n",
            "2021-01-13 12:00:06,715 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:00:06,907 - INFO - allennlp.training.trainer - Epoch duration: 0:01:31.068748\n",
            "2021-01-13 12:00:06,908 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:09:33\n",
            "2021-01-13 12:00:06,908 - INFO - allennlp.training.trainer - Epoch 5/99\n",
            "2021-01-13 12:00:06,908 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:00:06,909 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.9412, loss: 4.4444 ||: 100%|##########| 22/22 [01:17<00:00,  3.52s/it]\n",
            "2021-01-13 12:01:24,387 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.9287, loss: 6.9927 ||: 100%|##########| 8/8 [00:05<00:00,  1.46it/s]\n",
            "2021-01-13 12:01:29,867 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:01:29,867 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:01:29,868 - INFO - allennlp.training.tensorboard_writer - loss               |     4.444  |     6.993\n",
            "2021-01-13 12:01:29,870 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:01:30,135 - INFO - allennlp.training.trainer - Epoch duration: 0:01:23.226482\n",
            "2021-01-13 12:01:30,135 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:08:33\n",
            "2021-01-13 12:01:30,135 - INFO - allennlp.training.trainer - Epoch 6/99\n",
            "2021-01-13 12:01:30,136 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:01:30,136 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.7975, loss: 4.3725 ||: 100%|##########| 22/22 [01:07<00:00,  3.05s/it]\n",
            "2021-01-13 12:02:37,362 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0055, batch_loss: 7.1121, loss: 6.9612 ||: 100%|##########| 8/8 [00:03<00:00,  2.03it/s]\n",
            "2021-01-13 12:02:41,313 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:02:41,314 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.006\n",
            "2021-01-13 12:02:41,315 - INFO - allennlp.training.tensorboard_writer - loss               |     4.372  |     6.961\n",
            "2021-01-13 12:02:41,316 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:02:41,461 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'Output_seq2seq//best.th'.\n",
            "2021-01-13 12:02:41,618 - INFO - allennlp.training.trainer - Epoch duration: 0:01:11.482915\n",
            "2021-01-13 12:02:41,619 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:04:50\n",
            "2021-01-13 12:02:41,619 - INFO - allennlp.training.trainer - Epoch 7/99\n",
            "2021-01-13 12:02:41,619 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:02:41,620 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.0838, loss: 4.3448 ||: 100%|##########| 22/22 [01:01<00:00,  2.81s/it]\n",
            "2021-01-13 12:03:43,668 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.0513, loss: 6.8048 ||: 100%|##########| 8/8 [00:05<00:00,  1.50it/s]\n",
            "2021-01-13 12:03:49,005 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:03:49,006 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:03:49,007 - INFO - allennlp.training.tensorboard_writer - loss               |     4.345  |     6.805\n",
            "2021-01-13 12:03:49,008 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:03:49,334 - INFO - allennlp.training.trainer - Epoch duration: 0:01:07.715014\n",
            "2021-01-13 12:03:49,335 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:01:02\n",
            "2021-01-13 12:03:49,335 - INFO - allennlp.training.trainer - Epoch 8/99\n",
            "2021-01-13 12:03:49,335 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:03:49,336 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.6708, loss: 4.3400 ||: 100%|##########| 22/22 [00:49<00:00,  2.27s/it]\n",
            "2021-01-13 12:04:39,314 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.2417, loss: 7.0594 ||: 100%|##########| 8/8 [00:05<00:00,  1.51it/s]\n",
            "2021-01-13 12:04:44,600 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:04:44,601 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:04:44,602 - INFO - allennlp.training.tensorboard_writer - loss               |     4.340  |     7.059\n",
            "2021-01-13 12:04:44,603 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:04:44,781 - INFO - allennlp.training.trainer - Epoch duration: 0:00:55.446457\n",
            "2021-01-13 12:04:44,782 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:55:46\n",
            "2021-01-13 12:04:44,782 - INFO - allennlp.training.trainer - Epoch 9/99\n",
            "2021-01-13 12:04:44,782 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:04:44,783 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.3958, loss: 4.3230 ||: 100%|##########| 22/22 [00:46<00:00,  2.11s/it]\n",
            "2021-01-13 12:05:31,299 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.1913, loss: 6.9743 ||: 100%|##########| 8/8 [00:04<00:00,  1.88it/s]\n",
            "2021-01-13 12:05:35,552 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:05:35,553 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:05:35,554 - INFO - allennlp.training.tensorboard_writer - loss               |     4.323  |     6.974\n",
            "2021-01-13 12:05:35,555 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:05:35,732 - INFO - allennlp.training.trainer - Epoch duration: 0:00:50.949481\n",
            "2021-01-13 12:05:35,733 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:50:41\n",
            "2021-01-13 12:05:35,734 - INFO - allennlp.training.trainer - Epoch 10/99\n",
            "2021-01-13 12:05:35,734 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:05:35,735 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.3078, loss: 4.2307 ||: 100%|##########| 22/22 [00:42<00:00,  1.91s/it]\n",
            "2021-01-13 12:06:17,888 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.8954, loss: 7.1650 ||: 100%|##########| 8/8 [00:04<00:00,  1.91it/s]\n",
            "2021-01-13 12:06:22,079 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:06:22,080 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:06:22,081 - INFO - allennlp.training.tensorboard_writer - loss               |     4.231  |     7.165\n",
            "2021-01-13 12:06:22,082 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:06:22,247 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.512903\n",
            "2021-01-13 12:06:22,247 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:45:46\n",
            "2021-01-13 12:06:22,247 - INFO - allennlp.training.trainer - Epoch 11/99\n",
            "2021-01-13 12:06:22,247 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:06:22,248 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.1970, loss: 4.1238 ||: 100%|##########| 22/22 [00:39<00:00,  1.80s/it]\n",
            "2021-01-13 12:07:02,052 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.1860, loss: 7.0451 ||: 100%|##########| 8/8 [00:05<00:00,  1.48it/s]\n",
            "2021-01-13 12:07:07,459 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:07:07,460 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:07:07,461 - INFO - allennlp.training.tensorboard_writer - loss               |     4.124  |     7.045\n",
            "2021-01-13 12:07:07,462 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:07:07,641 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.393213\n",
            "2021-01-13 12:07:07,641 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:41:25\n",
            "2021-01-13 12:07:07,641 - INFO - allennlp.training.trainer - Epoch 12/99\n",
            "2021-01-13 12:07:07,641 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:07:07,642 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.1824, loss: 4.1434 ||: 100%|##########| 22/22 [00:41<00:00,  1.90s/it]\n",
            "2021-01-13 12:07:49,567 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.0889, loss: 6.9803 ||: 100%|##########| 8/8 [00:05<00:00,  1.54it/s]\n",
            "2021-01-13 12:07:54,751 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:07:54,752 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:07:54,753 - INFO - allennlp.training.tensorboard_writer - loss               |     4.143  |     6.980\n",
            "2021-01-13 12:07:54,754 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:07:54,931 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.289297\n",
            "2021-01-13 12:07:54,931 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:37:50\n",
            "2021-01-13 12:07:54,931 - INFO - allennlp.training.trainer - Epoch 13/99\n",
            "2021-01-13 12:07:54,931 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:07:54,932 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 3.9500, loss: 4.1264 ||: 100%|##########| 22/22 [00:44<00:00,  2.01s/it]\n",
            "2021-01-13 12:08:39,337 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 8.0263, loss: 7.3068 ||: 100%|##########| 8/8 [00:05<00:00,  1.50it/s]\n",
            "2021-01-13 12:08:44,665 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:08:44,666 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:08:44,667 - INFO - allennlp.training.tensorboard_writer - loss               |     4.126  |     7.307\n",
            "2021-01-13 12:08:44,668 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:08:44,859 - INFO - allennlp.training.trainer - Epoch duration: 0:00:49.927817\n",
            "2021-01-13 12:08:44,859 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:34:54\n",
            "2021-01-13 12:08:44,860 - INFO - allennlp.training.trainer - Epoch 14/99\n",
            "2021-01-13 12:08:44,860 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:08:44,861 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.1824, loss: 4.1066 ||: 100%|##########| 22/22 [00:42<00:00,  1.92s/it]\n",
            "2021-01-13 12:09:27,134 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.2476, loss: 7.0805 ||: 100%|##########| 8/8 [00:05<00:00,  1.58it/s]\n",
            "2021-01-13 12:09:32,208 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:09:32,209 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:09:32,210 - INFO - allennlp.training.tensorboard_writer - loss               |     4.107  |     7.080\n",
            "2021-01-13 12:09:32,211 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:09:32,384 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.524499\n",
            "2021-01-13 12:09:32,385 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:32:02\n",
            "2021-01-13 12:09:32,385 - INFO - allennlp.training.trainer - Epoch 15/99\n",
            "2021-01-13 12:09:32,385 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:09:32,386 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.2111, loss: 3.9896 ||: 100%|##########| 22/22 [00:33<00:00,  1.53s/it]\n",
            "2021-01-13 12:10:06,065 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.7881, loss: 7.3874 ||: 100%|##########| 8/8 [00:05<00:00,  1.60it/s]\n",
            "2021-01-13 12:10:11,075 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:10:11,076 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:10:11,077 - INFO - allennlp.training.tensorboard_writer - loss               |     3.990  |     7.387\n",
            "2021-01-13 12:10:11,078 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:10:11,250 - INFO - allennlp.training.trainer - Epoch duration: 0:00:38.865226\n",
            "2021-01-13 12:10:11,251 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:28:40\n",
            "2021-01-13 12:10:11,251 - INFO - allennlp.training.trainer - Epoch 16/99\n",
            "2021-01-13 12:10:11,251 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:10:11,252 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.5048, loss: 3.9985 ||: 100%|##########| 22/22 [00:32<00:00,  1.48s/it]\n",
            "2021-01-13 12:10:43,872 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.7748, loss: 7.4379 ||: 100%|##########| 8/8 [00:04<00:00,  1.64it/s]\n",
            "2021-01-13 12:10:48,742 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:10:48,742 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:10:48,743 - INFO - allennlp.training.tensorboard_writer - loss               |     3.999  |     7.438\n",
            "2021-01-13 12:10:48,744 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:10:48,910 - INFO - allennlp.training.trainer - Epoch duration: 0:00:37.658394\n",
            "2021-01-13 12:10:48,910 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:25:31\n",
            "2021-01-13 12:10:48,910 - INFO - allennlp.training.trainer - Epoch 17/99\n",
            "2021-01-13 12:10:48,910 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:10:48,911 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 3.8739, loss: 4.0136 ||: 100%|##########| 22/22 [00:31<00:00,  1.45s/it]\n",
            "2021-01-13 12:11:20,913 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.1410, loss: 7.2344 ||: 100%|##########| 8/8 [00:04<00:00,  1.66it/s]\n",
            "2021-01-13 12:11:25,747 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:11:25,747 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:11:25,748 - INFO - allennlp.training.tensorboard_writer - loss               |     4.014  |     7.234\n",
            "2021-01-13 12:11:25,749 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:11:25,893 - INFO - allennlp.training.trainer - Epoch duration: 0:00:36.982772\n",
            "2021-01-13 12:11:25,893 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:22:36\n",
            "2021-01-13 12:11:25,894 - INFO - allennlp.training.trainer - Epoch 18/99\n",
            "2021-01-13 12:11:25,894 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:11:25,894 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 3.9927, loss: 4.1272 ||: 100%|##########| 22/22 [00:31<00:00,  1.45s/it]\n",
            "2021-01-13 12:11:57,912 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.2722, loss: 7.4227 ||: 100%|##########| 8/8 [00:06<00:00,  1.31it/s]\n",
            "2021-01-13 12:12:04,016 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:12:04,017 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:12:04,018 - INFO - allennlp.training.tensorboard_writer - loss               |     4.127  |     7.423\n",
            "2021-01-13 12:12:04,019 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:12:04,182 - INFO - allennlp.training.trainer - Epoch duration: 0:00:38.288019\n",
            "2021-01-13 12:12:04,182 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:20:01\n",
            "2021-01-13 12:12:04,182 - INFO - allennlp.training.trainer - Epoch 19/99\n",
            "2021-01-13 12:12:04,183 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:12:04,183 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.5485, loss: 4.0508 ||: 100%|##########| 22/22 [00:30<00:00,  1.38s/it]\n",
            "2021-01-13 12:12:34,529 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.5100, loss: 7.3817 ||: 100%|##########| 8/8 [00:03<00:00,  2.13it/s]\n",
            "2021-01-13 12:12:38,283 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:12:38,284 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:12:38,285 - INFO - allennlp.training.tensorboard_writer - loss               |     4.051  |     7.382\n",
            "2021-01-13 12:12:38,286 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:12:38,455 - INFO - allennlp.training.trainer - Epoch duration: 0:00:34.272090\n",
            "2021-01-13 12:12:38,455 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:17:22\n",
            "2021-01-13 12:12:38,456 - INFO - allennlp.training.trainer - Epoch 20/99\n",
            "2021-01-13 12:12:38,456 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:12:38,457 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.4659, loss: 4.0041 ||: 100%|##########| 22/22 [00:31<00:00,  1.43s/it]\n",
            "2021-01-13 12:13:09,945 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.8254, loss: 7.4609 ||: 100%|##########| 8/8 [00:04<00:00,  1.96it/s]\n",
            "2021-01-13 12:13:14,041 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:13:14,041 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:13:14,042 - INFO - allennlp.training.tensorboard_writer - loss               |     4.004  |     7.461\n",
            "2021-01-13 12:13:14,043 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:13:14,216 - INFO - allennlp.training.trainer - Epoch duration: 0:00:35.760655\n",
            "2021-01-13 12:13:14,217 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:15:00\n",
            "2021-01-13 12:13:14,217 - INFO - allennlp.training.trainer - Epoch 21/99\n",
            "2021-01-13 12:13:14,218 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:13:14,219 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.4331, loss: 3.9994 ||: 100%|##########| 22/22 [00:30<00:00,  1.38s/it]\n",
            "2021-01-13 12:13:44,628 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.6233, loss: 7.3514 ||: 100%|##########| 8/8 [00:05<00:00,  1.49it/s]\n",
            "2021-01-13 12:13:50,011 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:13:50,012 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:13:50,013 - INFO - allennlp.training.tensorboard_writer - loss               |     3.999  |     7.351\n",
            "2021-01-13 12:13:50,014 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:13:50,433 - INFO - allennlp.training.trainer - Epoch duration: 0:00:36.215746\n",
            "2021-01-13 12:13:50,436 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:12:50\n",
            "2021-01-13 12:13:50,437 - INFO - allennlp.training.trainer - Epoch 22/99\n",
            "2021-01-13 12:13:50,437 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:13:50,438 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.6997, loss: 3.9576 ||: 100%|##########| 22/22 [00:30<00:00,  1.37s/it]\n",
            "2021-01-13 12:14:20,863 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.8320, loss: 7.4225 ||: 100%|##########| 8/8 [00:05<00:00,  1.59it/s]\n",
            "2021-01-13 12:14:25,910 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:14:25,910 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:14:25,911 - INFO - allennlp.training.tensorboard_writer - loss               |     3.958  |     7.423\n",
            "2021-01-13 12:14:25,912 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:14:26,159 - INFO - allennlp.training.trainer - Epoch duration: 0:00:35.721947\n",
            "2021-01-13 12:14:26,159 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:10:46\n",
            "2021-01-13 12:14:26,160 - INFO - allennlp.training.trainer - Epoch 23/99\n",
            "2021-01-13 12:14:26,160 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:14:26,161 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.6531, loss: 4.0336 ||: 100%|##########| 22/22 [00:33<00:00,  1.53s/it]\n",
            "2021-01-13 12:15:00,008 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.4474, loss: 7.4917 ||: 100%|##########| 8/8 [00:06<00:00,  1.30it/s]\n",
            "2021-01-13 12:15:06,182 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:15:06,183 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:15:06,185 - INFO - allennlp.training.tensorboard_writer - loss               |     4.034  |     7.492\n",
            "2021-01-13 12:15:06,186 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:15:06,410 - INFO - allennlp.training.trainer - Epoch duration: 0:00:40.250304\n",
            "2021-01-13 12:15:06,411 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:09:03\n",
            "2021-01-13 12:15:06,411 - INFO - allennlp.training.trainer - Epoch 24/99\n",
            "2021-01-13 12:15:06,411 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:15:06,412 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.0403, loss: 3.9782 ||: 100%|##########| 22/22 [00:34<00:00,  1.57s/it]\n",
            "2021-01-13 12:15:41,132 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 6.9246, loss: 7.3706 ||: 100%|##########| 8/8 [00:04<00:00,  1.67it/s]\n",
            "2021-01-13 12:15:45,921 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:15:45,922 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:15:45,923 - INFO - allennlp.training.tensorboard_writer - loss               |     3.978  |     7.371\n",
            "2021-01-13 12:15:45,923 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:15:46,098 - INFO - allennlp.training.trainer - Epoch duration: 0:00:39.687372\n",
            "2021-01-13 12:15:46,099 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:07:24\n",
            "2021-01-13 12:15:46,099 - INFO - allennlp.training.trainer - Epoch 25/99\n",
            "2021-01-13 12:15:46,099 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:15:46,100 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.0649, loss: 3.9000 ||: 100%|##########| 22/22 [00:35<00:00,  1.63s/it]\n",
            "2021-01-13 12:16:22,148 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 8.1081, loss: 7.5279 ||: 100%|##########| 8/8 [00:06<00:00,  1.33it/s]\n",
            "2021-01-13 12:16:28,152 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2021-01-13 12:16:28,153 - INFO - allennlp.training.tensorboard_writer - BLEU               |       N/A  |     0.000\n",
            "2021-01-13 12:16:28,154 - INFO - allennlp.training.tensorboard_writer - loss               |     3.900  |     7.528\n",
            "2021-01-13 12:16:28,155 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  5114.957  |       N/A\n",
            "2021-01-13 12:16:28,314 - INFO - allennlp.training.trainer - Epoch duration: 0:00:42.215412\n",
            "2021-01-13 12:16:28,315 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:05:57\n",
            "2021-01-13 12:16:28,315 - INFO - allennlp.training.trainer - Epoch 26/99\n",
            "2021-01-13 12:16:28,315 - INFO - allennlp.training.trainer - Worker 0 memory usage: 5.0G\n",
            "2021-01-13 12:16:28,315 - INFO - allennlp.training.trainer - Training\n",
            "batch_loss: 4.0064, loss: 3.9485 ||: 100%|##########| 22/22 [00:31<00:00,  1.44s/it]\n",
            "2021-01-13 12:17:00,046 - INFO - allennlp.training.trainer - Validating\n",
            "BLEU: 0.0000, batch_loss: 7.9425, loss: 7.4784 ||: 100%|##########| 8/8 [00:04<00:00,  1.68it/s]\n",
            "2021-01-13 12:17:04,801 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.\n",
            "2021-01-13 12:17:04,801 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2021-01-13 12:17:04,906 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 6,\n",
            "  \"peak_worker_0_memory_MB\": 5114.95703125,\n",
            "  \"training_duration\": \"0:23:10.360754\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 25,\n",
            "  \"epoch\": 25,\n",
            "  \"training_loss\": 3.9000268415971235,\n",
            "  \"training_worker_0_memory_MB\": 5114.95703125,\n",
            "  \"validation_BLEU\": 4.810231474292035e-09,\n",
            "  \"validation_loss\": 7.527891159057617,\n",
            "  \"best_validation_BLEU\": 0.005531317466497624,\n",
            "  \"best_validation_loss\": 6.961237788200378\n",
            "}\n",
            "2021-01-13 12:17:04,908 - INFO - allennlp.models.archival - archiving weights and vocabulary to Output_seq2seq/model.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9IcCbKQG3SW"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zLW4iv1anay"
      },
      "source": [
        "!allennlp evaluate 'Output_seq2seq/model.tar.gz' '/content/gdrive/My Drive/Kaggle/LYRICS_DATASET_test_with_title_seq.csv' --include-package information_retrieval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOoAAAvixBv9"
      },
      "source": [
        "!allennlp evaluate 'Output_seq2seq/model.tar.gz' '/content/gdrive/My Drive/Kaggle/LYRICS_DATASET_test_without_title_seq.csv' --include-package information_retrieval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZElYOyCkG6bi"
      },
      "source": [
        "# Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQbINZ_0aunF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a37a6f6-e4c4-40ac-f7ab-b1dba83a6e32"
      },
      "source": [
        "!allennlp predict  'Output_seq2seq/model.tar.gz' 'predictions/rejoice_seq.json'  --predictor seq2seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-13 12:23:33.516774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-13 12:23:37,011 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n",
            "2021-01-13 12:23:37,019 - INFO - allennlp.models.archival - loading archive file Output_seq2seq/model.tar.gz\n",
            "2021-01-13 12:23:37,019 - INFO - allennlp.models.archival - extracting archive file Output_seq2seq/model.tar.gz to temp dir /tmp/tmpuntzy9xm\n",
            "2021-01-13 12:23:37,333 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:23:37,334 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:23:37,334 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:23:37,334 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:23:37,334 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:23:37,334 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:23:37,335 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:23:37,336 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:23:37,337 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:23:37,338 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:23:37,339 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-01-13 12:23:37,339 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpuntzy9xm/vocabulary.\n",
            "2021-01-13 12:23:37,346 - INFO - allennlp.common.params - model.type = composed_seq2seq\n",
            "2021-01-13 12:23:37,346 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.type = basic\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.type = embedding\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.embedding_dim = 256\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.num_embeddings = None\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.projection_dim = None\n",
            "2021-01-13 12:23:37,347 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.weight = None\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.padding_index = None\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.trainable = True\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.max_norm = None\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.norm_type = 2.0\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.sparse = False\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
            "2021-01-13 12:23:37,348 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.pretrained_file = None\n",
            "2021-01-13 12:23:37,361 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
            "2021-01-13 12:23:37,361 - INFO - allennlp.common.params - model.encoder.input_dim = 256\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.hidden_dim = 256\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:23:37,362 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:23:37,366 - INFO - allennlp.common.params - model.decoder.type = auto_regressive_seq_decoder\n",
            "2021-01-13 12:23:37,366 - INFO - allennlp.common.params - model.decoder.decoder_net.type = stacked_self_attention\n",
            "2021-01-13 12:23:37,366 - INFO - allennlp.common.params - model.decoder.decoder_net.decoding_dim = 256\n",
            "2021-01-13 12:23:37,366 - INFO - allennlp.common.params - model.decoder.decoder_net.target_embedding_dim = 256\n",
            "2021-01-13 12:23:37,366 - INFO - allennlp.common.params - model.decoder.decoder_net.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.num_layers = 1\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.num_attention_heads = 8\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.use_positional_encoding = True\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.positional_encoding_max_steps = 5000\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.dropout_prob = 0.1\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:23:37,367 - INFO - allennlp.common.params - model.decoder.decoder_net.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:23:37,389 - INFO - allennlp.common.params - model.decoder.max_decoding_steps = 20\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.embedding_dim = 256\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.num_embeddings = None\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.projection_dim = None\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.weight = None\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.padding_index = None\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.trainable = True\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.max_norm = None\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.norm_type = 2.0\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.scale_grad_by_freq = False\n",
            "2021-01-13 12:23:37,390 - INFO - allennlp.common.params - model.decoder.target_embedder.sparse = False\n",
            "2021-01-13 12:23:37,391 - INFO - allennlp.common.params - model.decoder.target_embedder.vocab_namespace = tokens\n",
            "2021-01-13 12:23:37,391 - INFO - allennlp.common.params - model.decoder.target_embedder.pretrained_file = None\n",
            "2021-01-13 12:23:37,402 - INFO - allennlp.common.params - model.decoder.target_namespace = tokens\n",
            "2021-01-13 12:23:37,403 - INFO - allennlp.common.params - model.decoder.tie_output_embedding = False\n",
            "2021-01-13 12:23:37,403 - INFO - allennlp.common.params - model.decoder.scheduled_sampling_ratio = 0.5\n",
            "2021-01-13 12:23:37,403 - INFO - allennlp.common.params - model.decoder.label_smoothing_ratio = None\n",
            "2021-01-13 12:23:37,403 - INFO - allennlp.common.params - model.decoder.beam_size = 8\n",
            "2021-01-13 12:23:37,403 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.type = bleu\n",
            "2021-01-13 12:23:37,404 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.ngram_weights = [0.5, 0.5, 0, 0, 0]\n",
            "2021-01-13 12:23:37,404 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.exclude_indices = None\n",
            "2021-01-13 12:23:37,404 - INFO - allennlp.common.params - model.decoder.token_based_metric = None\n",
            "2021-01-13 12:23:37,417 - INFO - allennlp.common.params - model.tied_source_embedder_key = None\n",
            "2021-01-13 12:23:37,417 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f6dcdf91f60>\n",
            "2021-01-13 12:23:37,417 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-13 12:23:37,418 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.bias\n",
            "2021-01-13 12:23:37,419 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _decoder.target_embedder.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-13 12:23:37,420 - INFO - allennlp.nn.initializers -    _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-13 12:23:37,462 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpuntzy9xm\n",
            "input 0:  {\"source\": \"all of my friends live in a plastic bag walking around jumping the train tracks over the fence veins all black sleep on a bench in the park on my birthday call the blue lights cursed your name when i find im still awake  give me everything good and ill throw it away i wish i could quit but i cant stand the shakes choking to smoke or singing your praise but i think theres a god and he hears either way when i rejoice and complain i never know what to say  but i think theres a god and he hears either way when i rejoice and complain lift my voice that i was made and somebodys listening at night with the ghosts of my friends when i pray asking why did you let them leave and then make me stay know my name and all of my hideous mistakes  i rejoice i rejoice i rejoice i rejoice\"}\n",
            "prediction:  {\"class_log_probabilities\": [-4.434146881103516, -4.695529460906982, -4.763678550720215, -4.79652738571167, -5.072579383850098, -5.0840678215026855, -5.17653226852417, -5.805755138397217], \"predictions\": [[47, 22], [2, 22], [642, 22], [157, 22], [742, 22], [183, 22], [3, 22], [87, 22]], \"predicted_tokens\": [\"time\"]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHNcYTNb1RXf",
        "outputId": "5a55b319-84a3-462f-ab3f-924f41d61e7e"
      },
      "source": [
        "!allennlp predict  'Output_seq2seq/model.tar.gz' 'predictions/baby_one_more_time_seq.json'  --predictor seq2seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-13 12:24:06.699802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-13 12:24:10,485 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n",
            "2021-01-13 12:24:10,492 - INFO - allennlp.models.archival - loading archive file Output_seq2seq/model.tar.gz\n",
            "2021-01-13 12:24:10,492 - INFO - allennlp.models.archival - extracting archive file Output_seq2seq/model.tar.gz to temp dir /tmp/tmpyzne1ffi\n",
            "2021-01-13 12:24:10,839 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:24:10,840 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:24:10,841 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:24:10,842 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:24:10,843 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-01-13 12:24:10,843 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpyzne1ffi/vocabulary.\n",
            "2021-01-13 12:24:10,852 - INFO - allennlp.common.params - model.type = composed_seq2seq\n",
            "2021-01-13 12:24:10,852 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-01-13 12:24:10,852 - INFO - allennlp.common.params - model.source_text_embedder.type = basic\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.type = embedding\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.embedding_dim = 256\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.num_embeddings = None\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.projection_dim = None\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.weight = None\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.padding_index = None\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.trainable = True\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.max_norm = None\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.norm_type = 2.0\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
            "2021-01-13 12:24:10,853 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.sparse = False\n",
            "2021-01-13 12:24:10,854 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
            "2021-01-13 12:24:10,854 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.pretrained_file = None\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.input_dim = 256\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.hidden_dim = 256\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
            "2021-01-13 12:24:10,872 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
            "2021-01-13 12:24:10,873 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
            "2021-01-13 12:24:10,873 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:24:10,873 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:24:10,876 - INFO - allennlp.common.params - model.decoder.type = auto_regressive_seq_decoder\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.type = stacked_self_attention\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.decoding_dim = 256\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.target_embedding_dim = 256\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.num_layers = 1\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.num_attention_heads = 8\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.use_positional_encoding = True\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.positional_encoding_max_steps = 5000\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.dropout_prob = 0.1\n",
            "2021-01-13 12:24:10,877 - INFO - allennlp.common.params - model.decoder.decoder_net.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:24:10,878 - INFO - allennlp.common.params - model.decoder.decoder_net.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:24:10,912 - INFO - allennlp.common.params - model.decoder.max_decoding_steps = 20\n",
            "2021-01-13 12:24:10,912 - INFO - allennlp.common.params - model.decoder.target_embedder.embedding_dim = 256\n",
            "2021-01-13 12:24:10,912 - INFO - allennlp.common.params - model.decoder.target_embedder.num_embeddings = None\n",
            "2021-01-13 12:24:10,912 - INFO - allennlp.common.params - model.decoder.target_embedder.projection_dim = None\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.weight = None\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.padding_index = None\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.trainable = True\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.max_norm = None\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.norm_type = 2.0\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.scale_grad_by_freq = False\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.sparse = False\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.vocab_namespace = tokens\n",
            "2021-01-13 12:24:10,913 - INFO - allennlp.common.params - model.decoder.target_embedder.pretrained_file = None\n",
            "2021-01-13 12:24:10,929 - INFO - allennlp.common.params - model.decoder.target_namespace = tokens\n",
            "2021-01-13 12:24:10,930 - INFO - allennlp.common.params - model.decoder.tie_output_embedding = False\n",
            "2021-01-13 12:24:10,930 - INFO - allennlp.common.params - model.decoder.scheduled_sampling_ratio = 0.5\n",
            "2021-01-13 12:24:10,930 - INFO - allennlp.common.params - model.decoder.label_smoothing_ratio = None\n",
            "2021-01-13 12:24:10,930 - INFO - allennlp.common.params - model.decoder.beam_size = 8\n",
            "2021-01-13 12:24:10,930 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.type = bleu\n",
            "2021-01-13 12:24:10,931 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.ngram_weights = [0.5, 0.5, 0, 0, 0]\n",
            "2021-01-13 12:24:10,931 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.exclude_indices = None\n",
            "2021-01-13 12:24:10,931 - INFO - allennlp.common.params - model.decoder.token_based_metric = None\n",
            "2021-01-13 12:24:10,945 - INFO - allennlp.common.params - model.tied_source_embedder_key = None\n",
            "2021-01-13 12:24:10,946 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fbe196e2f60>\n",
            "2021-01-13 12:24:10,946 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-01-13 12:24:10,946 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-01-13 12:24:10,946 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-13 12:24:10,947 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.bias\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.weight\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _decoder.target_embedder.weight\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-13 12:24:10,948 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-13 12:24:10,949 - INFO - allennlp.nn.initializers -    _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-13 12:24:10,988 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpyzne1ffi\n",
            "input 0:  {\"source\": \"oh baby baby how was i supposed to know that something wasnt right here oh baby baby i shouldnt have let you go cause now youre out of sight yeah   show me how you want it to be tell me baby cause i need to know now oh because   my loneliness is killing me and i i must confess i still believe still believe when youre not with me i lose my mind give me a sign hit me baby one more time   oh baby baby the reason i breathe is you yeah you got me stranded oh pretty baby theres nothing that i wouldnt do its not the way i planned it   show me how you want it to be oh tell me babe cause i need to know now oh because   my loneliness is killing me and i i must confess i still believe still believe when youre not with me i lose my mind give me a sign hit me baby one more time   oh baby baby how was i supposed to know oh pretty baby i shouldntve let you go   oh i must confess that my loneliness is killing me now hit me baby one more time   my loneliness is killing me and i i must confess i still believe still believe when youre not with me i lose my mind give me a sign hit me baby one more time when im not with you i lose my mind give me a sign hit me baby one more time\"}\n",
            "prediction:  {\"class_log_probabilities\": [-4.441864013671875, -4.6906843185424805, -4.765979290008545, -4.802639484405518, -5.080842971801758, -5.093632221221924, -5.173525333404541, -5.81077766418457], \"predictions\": [[47, 22], [2, 22], [642, 22], [157, 22], [742, 22], [183, 22], [3, 22], [87, 22]], \"predicted_tokens\": [\"time\"]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmzZQ7KVTU0s",
        "outputId": "a5017e44-962d-4440-da07-4eff15235778"
      },
      "source": [
        "!allennlp predict  'Output_seq2seq/model.tar.gz' 'predictions/when_the_god_of_love_returns_therell_be_hell_to_pay_seq.json'  --predictor seq2seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-13 12:24:19.103006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-13 12:24:22,637 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n",
            "2021-01-13 12:24:22,644 - INFO - allennlp.models.archival - loading archive file Output_seq2seq/model.tar.gz\n",
            "2021-01-13 12:24:22,644 - INFO - allennlp.models.archival - extracting archive file Output_seq2seq/model.tar.gz to temp dir /tmp/tmpuqnck5on\n",
            "2021-01-13 12:24:22,978 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:24:22,979 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:24:22,979 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:24:22,979 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:24:22,979 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:24:22,979 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:24:22,980 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-13 12:24:22,981 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-13 12:24:22,982 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-13 12:24:22,983 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-01-13 12:24:22,984 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpuqnck5on/vocabulary.\n",
            "2021-01-13 12:24:22,992 - INFO - allennlp.common.params - model.type = composed_seq2seq\n",
            "2021-01-13 12:24:22,992 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-01-13 12:24:22,992 - INFO - allennlp.common.params - model.source_text_embedder.type = basic\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.type = embedding\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.embedding_dim = 256\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.num_embeddings = None\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.projection_dim = None\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.weight = None\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.padding_index = None\n",
            "2021-01-13 12:24:22,993 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.trainable = True\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.max_norm = None\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.norm_type = 2.0\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.sparse = False\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
            "2021-01-13 12:24:22,994 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.pretrained_file = None\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.input_dim = 256\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.hidden_dim = 256\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:24:23,014 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
            "2021-01-13 12:24:23,015 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
            "2021-01-13 12:24:23,015 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
            "2021-01-13 12:24:23,015 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
            "2021-01-13 12:24:23,015 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:24:23,015 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:24:23,019 - INFO - allennlp.common.params - model.decoder.type = auto_regressive_seq_decoder\n",
            "2021-01-13 12:24:23,019 - INFO - allennlp.common.params - model.decoder.decoder_net.type = stacked_self_attention\n",
            "2021-01-13 12:24:23,019 - INFO - allennlp.common.params - model.decoder.decoder_net.decoding_dim = 256\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.target_embedding_dim = 256\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.feedforward_hidden_dim = 128\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.num_layers = 1\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.num_attention_heads = 8\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.use_positional_encoding = True\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.positional_encoding_max_steps = 5000\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.dropout_prob = 0.1\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.residual_dropout_prob = 0.2\n",
            "2021-01-13 12:24:23,020 - INFO - allennlp.common.params - model.decoder.decoder_net.attention_dropout_prob = 0.1\n",
            "2021-01-13 12:24:23,052 - INFO - allennlp.common.params - model.decoder.max_decoding_steps = 20\n",
            "2021-01-13 12:24:23,052 - INFO - allennlp.common.params - model.decoder.target_embedder.embedding_dim = 256\n",
            "2021-01-13 12:24:23,052 - INFO - allennlp.common.params - model.decoder.target_embedder.num_embeddings = None\n",
            "2021-01-13 12:24:23,052 - INFO - allennlp.common.params - model.decoder.target_embedder.projection_dim = None\n",
            "2021-01-13 12:24:23,052 - INFO - allennlp.common.params - model.decoder.target_embedder.weight = None\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.padding_index = None\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.trainable = True\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.max_norm = None\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.norm_type = 2.0\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.scale_grad_by_freq = False\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.sparse = False\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.vocab_namespace = tokens\n",
            "2021-01-13 12:24:23,053 - INFO - allennlp.common.params - model.decoder.target_embedder.pretrained_file = None\n",
            "2021-01-13 12:24:23,069 - INFO - allennlp.common.params - model.decoder.target_namespace = tokens\n",
            "2021-01-13 12:24:23,069 - INFO - allennlp.common.params - model.decoder.tie_output_embedding = False\n",
            "2021-01-13 12:24:23,069 - INFO - allennlp.common.params - model.decoder.scheduled_sampling_ratio = 0.5\n",
            "2021-01-13 12:24:23,069 - INFO - allennlp.common.params - model.decoder.label_smoothing_ratio = None\n",
            "2021-01-13 12:24:23,069 - INFO - allennlp.common.params - model.decoder.beam_size = 8\n",
            "2021-01-13 12:24:23,070 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.type = bleu\n",
            "2021-01-13 12:24:23,070 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.ngram_weights = [0.5, 0.5, 0, 0, 0]\n",
            "2021-01-13 12:24:23,070 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.exclude_indices = None\n",
            "2021-01-13 12:24:23,070 - INFO - allennlp.common.params - model.decoder.token_based_metric = None\n",
            "2021-01-13 12:24:23,088 - INFO - allennlp.common.params - model.tied_source_embedder_key = None\n",
            "2021-01-13 12:24:23,088 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f6e4db80f60>\n",
            "2021-01-13 12:24:23,088 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-13 12:24:23,089 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _decoder.target_embedder.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-13 12:24:23,090 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-13 12:24:23,091 - INFO - allennlp.nn.initializers -    _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-13 12:24:23,128 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpuqnck5on\n",
            "input 0:  {\"source\": \"when the god of love returns therell be hell to pay though the world may be out of excuses i know just what i would say: let the seven trumpets sound as a locust sky grows dark but first lets take you on a quick tour of your creations handiwork barely got through the prisons and stores and the pale horse looks a little sick says jesus you didnt leave a whole lot for me if this isnt hell already then tell me what the hell is   and we say its just human human nature this place is savage and unjust we crawled out of the darkness and endured your impatience were more than willing to adjust and now youve got the gall to judge us   the spider spins his web the tiger stalks his prey and we steal fire from the heavens to try to keep the night at bay every monster has a code one that steadies the shaking hand and hes determined to accrue more capital by whatever means he can   oh its just human human nature weve got these appetites to serve you must not know the first thing about human beings were the earths most soulful predator try something less ambitious the next time you get bored oh my lord   we just want light in the dark some warmth in the cold and to make something out of nothing sounds like someone else i know\"}\n",
            "prediction:  {\"class_log_probabilities\": [-4.439443111419678, -4.692176818847656, -4.765261173248291, -4.800760269165039, -5.078294277191162, -5.090646743774414, -5.174403190612793, -5.809198379516602], \"predictions\": [[47, 22], [2, 22], [642, 22], [157, 22], [742, 22], [183, 22], [3, 22], [87, 22]], \"predicted_tokens\": [\"time\"]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzj0YHIGjM4",
        "outputId": "5fffe08f-7666-4c0e-814d-fcb127dd34d2"
      },
      "source": [
        "!allennlp predict  'Output_seq2seq/model.tar.gz' 'predictions/brittle_boned_seq.json'  --predictor seq2seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-16 17:34:31.494972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-16 17:34:35,858 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n",
            "2021-01-16 17:34:35,868 - INFO - allennlp.models.archival - loading archive file Output_seq2seq/model.tar.gz\n",
            "2021-01-16 17:34:35,869 - INFO - allennlp.models.archival - extracting archive file Output_seq2seq/model.tar.gz to temp dir /tmp/tmph9jshav7\n",
            "2021-01-16 17:34:36,227 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-16 17:34:36,228 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-16 17:34:36,229 - INFO - allennlp.common.params - dataset_reader.type = seq2seq\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = whitespace\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.target_tokenizer.type = whitespace\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.source_token_indexers = None\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = None\n",
            "2021-01-16 17:34:36,230 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.source_add_end_token = True\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.target_add_start_token = True\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.target_add_end_token = True\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.start_symbol = @start@\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.end_symbol = @end@\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.delimiter = ,\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.source_max_tokens = None\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.target_max_tokens = None\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - dataset_reader.quoting = 0\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-01-16 17:34:36,231 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmph9jshav7/vocabulary.\n",
            "2021-01-16 17:34:36,239 - INFO - allennlp.common.params - model.type = composed_seq2seq\n",
            "2021-01-16 17:34:36,239 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.type = basic\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.type = embedding\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.embedding_dim = 256\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.num_embeddings = None\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.projection_dim = None\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.weight = None\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.padding_index = None\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.trainable = True\n",
            "2021-01-16 17:34:36,240 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.max_norm = None\n",
            "2021-01-16 17:34:36,241 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.norm_type = 2.0\n",
            "2021-01-16 17:34:36,241 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
            "2021-01-16 17:34:36,241 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.sparse = False\n",
            "2021-01-16 17:34:36,241 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
            "2021-01-16 17:34:36,241 - INFO - allennlp.common.params - model.source_text_embedder.token_embedders.tokens.pretrained_file = None\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.type = stacked_self_attention\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.input_dim = 256\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.hidden_dim = 256\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.projection_dim = 128\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.feedforward_hidden_dim = 128\n",
            "2021-01-16 17:34:36,254 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
            "2021-01-16 17:34:36,255 - INFO - allennlp.common.params - model.encoder.num_attention_heads = 8\n",
            "2021-01-16 17:34:36,255 - INFO - allennlp.common.params - model.encoder.use_positional_encoding = True\n",
            "2021-01-16 17:34:36,255 - INFO - allennlp.common.params - model.encoder.dropout_prob = 0.1\n",
            "2021-01-16 17:34:36,255 - INFO - allennlp.common.params - model.encoder.residual_dropout_prob = 0.2\n",
            "2021-01-16 17:34:36,255 - INFO - allennlp.common.params - model.encoder.attention_dropout_prob = 0.1\n",
            "2021-01-16 17:34:36,259 - INFO - allennlp.common.params - model.decoder.type = auto_regressive_seq_decoder\n",
            "2021-01-16 17:34:36,259 - INFO - allennlp.common.params - model.decoder.decoder_net.type = stacked_self_attention\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.decoding_dim = 256\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.target_embedding_dim = 256\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.feedforward_hidden_dim = 128\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.num_layers = 1\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.num_attention_heads = 8\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.use_positional_encoding = True\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.positional_encoding_max_steps = 5000\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.dropout_prob = 0.1\n",
            "2021-01-16 17:34:36,260 - INFO - allennlp.common.params - model.decoder.decoder_net.residual_dropout_prob = 0.2\n",
            "2021-01-16 17:34:36,261 - INFO - allennlp.common.params - model.decoder.decoder_net.attention_dropout_prob = 0.1\n",
            "2021-01-16 17:34:36,283 - INFO - allennlp.common.params - model.decoder.max_decoding_steps = 20\n",
            "2021-01-16 17:34:36,283 - INFO - allennlp.common.params - model.decoder.target_embedder.embedding_dim = 256\n",
            "2021-01-16 17:34:36,283 - INFO - allennlp.common.params - model.decoder.target_embedder.num_embeddings = None\n",
            "2021-01-16 17:34:36,283 - INFO - allennlp.common.params - model.decoder.target_embedder.projection_dim = None\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.weight = None\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.padding_index = None\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.trainable = True\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.max_norm = None\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.norm_type = 2.0\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.scale_grad_by_freq = False\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.sparse = False\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.vocab_namespace = tokens\n",
            "2021-01-16 17:34:36,284 - INFO - allennlp.common.params - model.decoder.target_embedder.pretrained_file = None\n",
            "2021-01-16 17:34:36,296 - INFO - allennlp.common.params - model.decoder.target_namespace = tokens\n",
            "2021-01-16 17:34:36,296 - INFO - allennlp.common.params - model.decoder.tie_output_embedding = False\n",
            "2021-01-16 17:34:36,296 - INFO - allennlp.common.params - model.decoder.scheduled_sampling_ratio = 0.5\n",
            "2021-01-16 17:34:36,297 - INFO - allennlp.common.params - model.decoder.label_smoothing_ratio = None\n",
            "2021-01-16 17:34:36,297 - INFO - allennlp.common.params - model.decoder.beam_size = 8\n",
            "2021-01-16 17:34:36,297 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.type = bleu\n",
            "2021-01-16 17:34:36,297 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.ngram_weights = [0.5, 0.5, 0, 0, 0]\n",
            "2021-01-16 17:34:36,297 - INFO - allennlp.common.params - model.decoder.tensor_based_metric.exclude_indices = None\n",
            "2021-01-16 17:34:36,298 - INFO - allennlp.common.params - model.decoder.token_based_metric = None\n",
            "2021-01-16 17:34:36,311 - INFO - allennlp.common.params - model.tied_source_embedder_key = None\n",
            "2021-01-16 17:34:36,311 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f2bce0b2240>\n",
            "2021-01-16 17:34:36,311 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.bias\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_1.weight\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.bias\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.feed_forward.w_2.weight\n",
            "2021-01-16 17:34:36,312 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.bias\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.0.weight\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.bias\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.1.weight\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.bias\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.2.weight\n",
            "2021-01-16 17:34:36,313 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.bias\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.self_attn.linears.3.weight\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.bias\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.0.weight\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.bias\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.1.weight\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.bias\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.2.weight\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.bias\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.src_attn.linears.3.weight\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.beta\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.0.norm.gamma\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.beta\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.1.norm.gamma\n",
            "2021-01-16 17:34:36,314 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.beta\n",
            "2021-01-16 17:34:36,315 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.layers.0.sublayer.2.norm.gamma\n",
            "2021-01-16 17:34:36,315 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.beta\n",
            "2021-01-16 17:34:36,315 - INFO - allennlp.nn.initializers -    _decoder._decoder_net._self_attention.norm.gamma\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.bias\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _decoder._output_projection_layer.weight\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _decoder.target_embedder.weight\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.bias\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.0.weight\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.bias\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_0._linear_layers.1.weight\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.beta\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.feedforward_layer_norm_0.gamma\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.beta\n",
            "2021-01-16 17:34:36,316 - INFO - allennlp.nn.initializers -    _encoder.layer_norm_0.gamma\n",
            "2021-01-16 17:34:36,317 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.bias\n",
            "2021-01-16 17:34:36,317 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._combined_projection.weight\n",
            "2021-01-16 17:34:36,317 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.bias\n",
            "2021-01-16 17:34:36,317 - INFO - allennlp.nn.initializers -    _encoder.self_attention_0._output_projection.weight\n",
            "2021-01-16 17:34:36,317 - INFO - allennlp.nn.initializers -    _source_text_embedder.token_embedder_tokens.weight\n",
            "2021-01-16 17:34:36,340 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmph9jshav7\n",
            "input 0:  {\"source\": \" the low electric glow \\u2013 static snows in the lobby dull tv magazines waiting rooms cant hide me from the sting paper sheets bloodwork and the iv and the whirring machines while the nurses reassure me: this will be quick and easy im not gonna feel a thing lie and say itll be alright like a stray falling asleep cause im so good at hurting myself  pulse is slow faint metronome on my left side beneath my protruding spine you can hardly hear at night white flag blindfold covering my sunken eyes and a line of rifles aimed at my sick mind  cause im so good at hurting myself\"}\n",
            "prediction:  {\"class_log_probabilities\": [-4.432049751281738, -4.697364807128906, -4.763139247894287, -4.794657230377197, -5.070094108581543, -5.081235408782959, -5.177950382232666, -5.804445743560791], \"predictions\": [[47, 22], [2, 22], [642, 22], [157, 22], [742, 22], [183, 22], [3, 22], [87, 22]], \"predicted_tokens\": [\"time\"]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}